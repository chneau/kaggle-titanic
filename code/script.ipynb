{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "\n",
    "leTitle = LabelEncoder()\n",
    "leTitle.fit([\"Mr\", \"Mrs\", 'Capt', 'Col', 'Countess', 'Don',\n",
    "             'Dr', 'Jonkheer', 'Lady', 'Major', 'Master',\n",
    "             'Miss', 'Mlle', 'Mme', 'Ms', 'Rev', 'Sir', 'Dona'])\n",
    "def process(df):\n",
    "    def add_title(cell): return re.search(' ([A-Za-z]+)\\\\.', cell).group(1)\n",
    "    df[\"Title\"] = df.apply(lambda row: add_title(row[\"Name\"]), axis=1)\n",
    "    df[\"Title\"] = leTitle.transform(df[\"Title\"])\n",
    "    df.drop(labels=[\"PassengerId\", \"Name\", \"Cabin\", \"Ticket\"], axis=1, inplace=True)\n",
    "    df['Sex'].replace([\"female\", \"male\"], [0, 1], inplace=True)\n",
    "    df['Embarked'].replace([\"Q\", \"C\", \"S\"], [0, 1, 2], inplace=True)\n",
    "    for column in [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"Sex\", \"Pclass\", \"Title\"]:\n",
    "        imputer = Imputer()\n",
    "        mmscal = MinMaxScaler()\n",
    "        df[column] = imputer.fit_transform(df[column].values.reshape(-1, 1))\n",
    "        df[column] = mmscal.fit_transform(df[column].values.reshape(-1, 1))\n",
    "    if \"Survived\" in df:\n",
    "        df = df[pd.notnull(df['SibSp'])]\n",
    "    return df\n",
    "\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    features = dict(features)\n",
    "    if labels is None:\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.452723</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287881</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.182382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393380</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.340630</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274693</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604378</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301068</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.828564</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass  Sex       Age  SibSp     Parch      Fare  Embarked     Title\n",
       "0      1.0  1.0  0.452723  0.000  0.000000  0.015282       0.0  0.800000\n",
       "1      1.0  0.0  0.617566  0.125  0.000000  0.013663       1.0  0.866667\n",
       "2      0.5  1.0  0.815377  0.000  0.000000  0.018909       0.0  0.800000\n",
       "3      1.0  1.0  0.353818  0.000  0.000000  0.016908       1.0  0.800000\n",
       "4      1.0  0.0  0.287881  0.125  0.111111  0.023984       1.0  0.866667\n",
       "5      1.0  1.0  0.182382  0.000  0.000000  0.018006       1.0  0.800000\n",
       "6      1.0  0.0  0.393380  0.000  0.000000  0.014891       0.0  0.600000\n",
       "7      0.5  1.0  0.340630  0.125  0.111111  0.056604       1.0  0.800000\n",
       "8      1.0  0.0  0.235131  0.000  0.000000  0.014110       0.5  0.866667\n",
       "9      1.0  1.0  0.274693  0.250  0.000000  0.047138       1.0  0.800000\n",
       "10     1.0  1.0  0.396975  0.000  0.000000  0.015412       1.0  0.800000\n",
       "11     0.0  1.0  0.604378  0.000  0.000000  0.050749       1.0  0.800000\n",
       "12     0.0  0.0  0.301068  0.125  0.000000  0.160574       1.0  0.866667\n",
       "13     0.5  1.0  0.828564  0.125  0.000000  0.050749       1.0  0.800000\n",
       "14     0.0  0.0  0.617566  0.125  0.000000  0.119406       1.0  0.866667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = process(df = pd.read_csv(r\"../input/train.csv\"))\n",
    "test_data = pd.read_csv(r\"../input/test.csv\")\n",
    "pid = test_data[\"PassengerId\"]\n",
    "test_data = process(df = test_data)\n",
    "train_x, train_y = train_data, train_data.pop(\"Survived\")\n",
    "\n",
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "    \n",
    "display(test_data[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmptf5i6vj1\n",
      "{'accuracy': 0.9023569, 'accuracy_baseline': 0.6161616, 'auc': 0.9584918, 'auc_precision_recall': 0.9511346, 'average_loss': 0.23288493, 'label/mean': 0.3838384, 'loss': 23.055609, 'prediction/mean': 0.40533426, 'global_step': 5000}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    hidden_units=[66, 66, 66],\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=0.1,\n",
    "      l1_regularization_strength=0.001\n",
    "    )\n",
    ")\n",
    "\n",
    "classifier.train(\n",
    "    input_fn = lambda:train_input_fn(train_x, train_y, 500),\n",
    "    steps = 5000\n",
    ")\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(train_x, train_y, 100)\n",
    ")\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892,0\n",
      "893,0\n",
      "894,0\n",
      "895,0\n",
      "896,0\n",
      "897,0\n",
      "898,0\n",
      "899,1\n",
      "900,1\n",
      "901,0\n",
      "902,0\n",
      "903,0\n",
      "904,1\n",
      "905,0\n",
      "906,1\n",
      "907,1\n",
      "908,0\n",
      "909,0\n",
      "910,0\n",
      "911,1\n",
      "912,1\n",
      "913,1\n",
      "914,1\n",
      "915,1\n",
      "916,0\n",
      "917,0\n",
      "918,1\n",
      "919,0\n",
      "920,0\n",
      "921,0\n",
      "922,0\n",
      "923,0\n",
      "924,1\n",
      "925,1\n",
      "926,1\n",
      "927,0\n",
      "928,0\n",
      "929,1\n",
      "930,0\n",
      "931,1\n",
      "932,0\n",
      "933,1\n",
      "934,0\n",
      "935,1\n",
      "936,1\n",
      "937,0\n",
      "938,0\n",
      "939,0\n",
      "940,1\n",
      "941,1\n",
      "942,0\n",
      "943,0\n",
      "944,1\n",
      "945,1\n",
      "946,0\n",
      "947,0\n",
      "948,0\n",
      "949,0\n",
      "950,0\n",
      "951,1\n",
      "952,0\n",
      "953,0\n",
      "954,0\n",
      "955,1\n",
      "956,1\n",
      "957,1\n",
      "958,0\n",
      "959,0\n",
      "960,1\n",
      "961,0\n",
      "962,1\n",
      "963,0\n",
      "964,0\n",
      "965,0\n",
      "966,1\n",
      "967,0\n",
      "968,0\n",
      "969,1\n",
      "970,0\n",
      "971,1\n",
      "972,1\n",
      "973,0\n",
      "974,1\n",
      "975,0\n",
      "976,0\n",
      "977,0\n",
      "978,1\n",
      "979,1\n",
      "980,1\n",
      "981,1\n",
      "982,0\n",
      "983,0\n",
      "984,1\n",
      "985,0\n",
      "986,0\n",
      "987,0\n",
      "988,1\n",
      "989,0\n",
      "990,1\n",
      "991,0\n",
      "992,1\n",
      "993,0\n",
      "994,0\n",
      "995,0\n",
      "996,1\n",
      "997,0\n",
      "998,0\n",
      "999,0\n",
      "1000,0\n",
      "1001,0\n",
      "1002,0\n",
      "1003,0\n",
      "1004,1\n",
      "1005,0\n",
      "1006,1\n",
      "1007,0\n",
      "1008,0\n",
      "1009,1\n",
      "1010,0\n",
      "1011,1\n",
      "1012,1\n",
      "1013,0\n",
      "1014,1\n",
      "1015,0\n",
      "1016,0\n",
      "1017,0\n",
      "1018,0\n",
      "1019,1\n",
      "1020,1\n",
      "1021,0\n",
      "1022,0\n",
      "1023,0\n",
      "1024,0\n",
      "1025,0\n",
      "1026,0\n",
      "1027,0\n",
      "1028,0\n",
      "1029,0\n",
      "1030,0\n",
      "1031,0\n",
      "1032,0\n",
      "1033,1\n",
      "1034,0\n",
      "1035,1\n",
      "1036,1\n",
      "1037,0\n",
      "1038,0\n",
      "1039,0\n",
      "1040,1\n",
      "1041,1\n",
      "1042,1\n",
      "1043,0\n",
      "1044,0\n",
      "1045,1\n",
      "1046,0\n",
      "1047,0\n",
      "1048,1\n",
      "1049,1\n",
      "1050,1\n",
      "1051,1\n",
      "1052,0\n",
      "1053,1\n",
      "1054,1\n",
      "1055,0\n",
      "1056,0\n",
      "1057,0\n",
      "1058,0\n",
      "1059,0\n",
      "1060,1\n",
      "1061,0\n",
      "1062,0\n",
      "1063,0\n",
      "1064,0\n",
      "1065,0\n",
      "1066,0\n",
      "1067,1\n",
      "1068,1\n",
      "1069,1\n",
      "1070,1\n",
      "1071,1\n",
      "1072,0\n",
      "1073,1\n",
      "1074,1\n",
      "1075,0\n",
      "1076,1\n",
      "1077,1\n",
      "1078,1\n",
      "1079,0\n",
      "1080,0\n",
      "1081,0\n",
      "1082,0\n",
      "1083,1\n",
      "1084,1\n",
      "1085,0\n",
      "1086,0\n",
      "1087,0\n",
      "1088,1\n",
      "1089,1\n",
      "1090,0\n",
      "1091,1\n",
      "1092,0\n",
      "1093,1\n",
      "1094,1\n",
      "1095,1\n",
      "1096,0\n",
      "1097,1\n",
      "1098,0\n",
      "1099,0\n",
      "1100,1\n",
      "1101,0\n",
      "1102,0\n",
      "1103,0\n",
      "1104,0\n",
      "1105,1\n",
      "1106,0\n",
      "1107,0\n",
      "1108,0\n",
      "1109,0\n",
      "1110,1\n",
      "1111,0\n",
      "1112,0\n",
      "1113,0\n",
      "1114,1\n",
      "1115,0\n",
      "1116,0\n",
      "1117,1\n",
      "1118,0\n",
      "1119,0\n",
      "1120,0\n",
      "1121,0\n",
      "1122,0\n",
      "1123,1\n",
      "1124,0\n",
      "1125,0\n",
      "1126,1\n",
      "1127,0\n",
      "1128,1\n",
      "1129,0\n",
      "1130,0\n",
      "1131,1\n",
      "1132,0\n",
      "1133,1\n",
      "1134,0\n",
      "1135,0\n",
      "1136,0\n",
      "1137,0\n",
      "1138,1\n",
      "1139,0\n",
      "1140,1\n",
      "1141,0\n",
      "1142,1\n",
      "1143,0\n",
      "1144,0\n",
      "1145,0\n",
      "1146,0\n",
      "1147,0\n",
      "1148,0\n",
      "1149,0\n",
      "1150,1\n",
      "1151,0\n",
      "1152,0\n",
      "1153,0\n",
      "1154,1\n",
      "1155,1\n",
      "1156,0\n",
      "1157,0\n",
      "1158,0\n",
      "1159,0\n",
      "1160,0\n",
      "1161,0\n",
      "1162,0\n",
      "1163,0\n",
      "1164,1\n",
      "1165,0\n",
      "1166,0\n",
      "1167,1\n",
      "1168,0\n",
      "1169,0\n",
      "1170,0\n",
      "1171,0\n",
      "1172,0\n",
      "1173,1\n",
      "1174,0\n",
      "1175,1\n",
      "1176,1\n",
      "1177,0\n",
      "1178,0\n",
      "1179,0\n",
      "1180,0\n",
      "1181,0\n",
      "1182,0\n",
      "1183,0\n",
      "1184,0\n",
      "1185,0\n",
      "1186,0\n",
      "1187,0\n",
      "1188,1\n",
      "1189,0\n",
      "1190,0\n",
      "1191,0\n",
      "1192,0\n",
      "1193,0\n",
      "1194,0\n",
      "1195,0\n",
      "1196,0\n",
      "1197,1\n",
      "1198,0\n",
      "1199,1\n",
      "1200,0\n",
      "1201,1\n",
      "1202,0\n",
      "1203,0\n",
      "1204,0\n",
      "1205,0\n",
      "1206,1\n",
      "1207,0\n",
      "1208,0\n",
      "1209,0\n",
      "1210,0\n",
      "1211,0\n",
      "1212,0\n",
      "1213,0\n",
      "1214,0\n",
      "1215,1\n",
      "1216,1\n",
      "1217,0\n",
      "1218,1\n",
      "1219,0\n",
      "1220,1\n",
      "1221,0\n",
      "1222,1\n",
      "1223,1\n",
      "1224,0\n",
      "1225,1\n",
      "1226,0\n",
      "1227,0\n",
      "1228,0\n",
      "1229,0\n",
      "1230,0\n",
      "1231,1\n",
      "1232,0\n",
      "1233,0\n",
      "1234,0\n",
      "1235,1\n",
      "1236,0\n",
      "1237,0\n",
      "1238,0\n",
      "1239,0\n",
      "1240,0\n",
      "1241,1\n",
      "1242,1\n",
      "1243,0\n",
      "1244,0\n",
      "1245,0\n",
      "1246,1\n",
      "1247,0\n",
      "1248,1\n",
      "1249,0\n",
      "1250,0\n",
      "1251,1\n",
      "1252,0\n",
      "1253,1\n",
      "1254,1\n",
      "1255,0\n",
      "1256,1\n",
      "1257,1\n",
      "1258,0\n",
      "1259,0\n",
      "1260,1\n",
      "1261,1\n",
      "1262,0\n",
      "1263,1\n",
      "1264,0\n",
      "1265,0\n",
      "1266,1\n",
      "1267,1\n",
      "1268,0\n",
      "1269,0\n",
      "1270,0\n",
      "1271,0\n",
      "1272,0\n",
      "1273,0\n",
      "1274,1\n",
      "1275,0\n",
      "1276,0\n",
      "1277,1\n",
      "1278,0\n",
      "1279,0\n",
      "1280,0\n",
      "1281,0\n",
      "1282,0\n",
      "1283,1\n",
      "1284,1\n",
      "1285,0\n",
      "1286,0\n",
      "1287,1\n",
      "1288,0\n",
      "1289,1\n",
      "1290,0\n",
      "1291,0\n",
      "1292,1\n",
      "1293,0\n",
      "1294,1\n",
      "1295,0\n",
      "1296,1\n",
      "1297,0\n",
      "1298,0\n",
      "1299,0\n",
      "1300,0\n",
      "1301,1\n",
      "1302,0\n",
      "1303,1\n",
      "1304,0\n",
      "1305,0\n",
      "1306,1\n",
      "1307,0\n",
      "1308,0\n",
      "1309,1\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(input_fn=lambda:eval_input_fn(test_data,labels=None,batch_size=100))\n",
    "template = '{},{}'\n",
    "for pred_dict, p in zip(predictions, pid):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    print(template.format(p, class_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
